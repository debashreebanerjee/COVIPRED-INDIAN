{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b454f779",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import graphviz\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, balanced_accuracy_score, f1_score, fbeta_score, brier_score_loss, recall_score\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.utils import resample\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from xgboost import plot_importance\n",
    "from sklearn.datasets import make_classification\n",
    "import lightgbm as lgb\n",
    "import multiprocessing\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29f0bff",
   "metadata": {},
   "source": [
    "# Reading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "54bfce48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Haemoglobin(gms%)</th>\n",
       "      <th>Total WBC Count(/Cumm)</th>\n",
       "      <th>Neutrophils(%)</th>\n",
       "      <th>Lymphocytes(%)</th>\n",
       "      <th>Eosinophils(%)</th>\n",
       "      <th>Monocytes(%)</th>\n",
       "      <th>Basophils(%)</th>\n",
       "      <th>Others</th>\n",
       "      <th>Total RBC Count(millions/Cu)</th>\n",
       "      <th>HCT(%)</th>\n",
       "      <th>MCV(f L)</th>\n",
       "      <th>MCH(pg)</th>\n",
       "      <th>MCHC(gms%)</th>\n",
       "      <th>RDWCV(%)</th>\n",
       "      <th>Platelet Count(Lakh / Cumm)</th>\n",
       "      <th>Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Male</td>\n",
       "      <td>63.0</td>\n",
       "      <td>11.6</td>\n",
       "      <td>10200</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.20</td>\n",
       "      <td>35.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>28.3</td>\n",
       "      <td>33.7</td>\n",
       "      <td>14.4</td>\n",
       "      <td>2.20</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>13.7</td>\n",
       "      <td>7100</td>\n",
       "      <td>63</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.36</td>\n",
       "      <td>40.1</td>\n",
       "      <td>92.0</td>\n",
       "      <td>31.3</td>\n",
       "      <td>34.1</td>\n",
       "      <td>14.1</td>\n",
       "      <td>2.48</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Male</td>\n",
       "      <td>63.0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>8500</td>\n",
       "      <td>59</td>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>33.5</td>\n",
       "      <td>84.0</td>\n",
       "      <td>27.9</td>\n",
       "      <td>33.3</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.68</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5500</td>\n",
       "      <td>45</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.73</td>\n",
       "      <td>42.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>29.7</td>\n",
       "      <td>33.4</td>\n",
       "      <td>14.3</td>\n",
       "      <td>2.34</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Male</td>\n",
       "      <td>19.0</td>\n",
       "      <td>13.2</td>\n",
       "      <td>5100</td>\n",
       "      <td>61</td>\n",
       "      <td>33</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.27</td>\n",
       "      <td>42.2</td>\n",
       "      <td>80.0</td>\n",
       "      <td>25.1</td>\n",
       "      <td>31.4</td>\n",
       "      <td>15.4</td>\n",
       "      <td>1.94</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Gender   Age  Haemoglobin(gms%)  Total WBC Count(/Cumm)  \\\n",
       "0           0    Male  63.0               11.6                   10200   \n",
       "1           1  Female  27.0               13.7                    7100   \n",
       "2           2    Male  63.0               11.1                    8500   \n",
       "3           3    Male  35.0               14.0                    5500   \n",
       "4           4    Male  19.0               13.2                    5100   \n",
       "\n",
       "   Neutrophils(%)  Lymphocytes(%)  Eosinophils(%)  Monocytes(%)  Basophils(%)  \\\n",
       "0              72              23               2             3             0   \n",
       "1              63              34               1             2             0   \n",
       "2              59              35               3             3             0   \n",
       "3              45              50               2             3             0   \n",
       "4              61              33               3             3             0   \n",
       "\n",
       "   Others  Total RBC Count(millions/Cu)  HCT(%)  MCV(f L)  MCH(pg)  \\\n",
       "0       0                          4.20    35.0      84.0     28.3   \n",
       "1       0                          4.36    40.1      92.0     31.3   \n",
       "2       0                          4.00    33.5      84.0     27.9   \n",
       "3       0                          4.73    42.0      89.0     29.7   \n",
       "4       0                          3.27    42.2      80.0     25.1   \n",
       "\n",
       "   MCHC(gms%)  RDWCV(%)  Platelet Count(Lakh / Cumm)    Result  \n",
       "0        33.7      14.4                         2.20  Negative  \n",
       "1        34.1      14.1                         2.48  Negative  \n",
       "2        33.3      14.0                         2.68  Negative  \n",
       "3        33.4      14.3                         2.34  Negative  \n",
       "4        31.4      15.4                         1.94  Negative  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv('../Data/Edited_bitsM.csv') # Contains 300 negatives and 36 positives from BITSM\n",
    "df2 = pd.read_csv('../Data/ESIdf.csv') # Contains 75 positives from ESI\n",
    "\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f734f09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the external dataset validation for Indian model\n",
    "external_validation_df = df1[df1['Result'] == 'Positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "711c2dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1[df1['Result'] != 'Positive'] # Removing positives from the training set of BITSM\n",
    "# Now, df1 contains 300 negatives from BITSM and df2 contains 75 positives from ESI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "10fd3e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the training dataset by merging df1 and df2\n",
    "df = pd.concat([df1, df2], join = 'inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee1f072",
   "metadata": {},
   "source": [
    "# Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "12c02735",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "\n",
    "df['Result'] = encoder.fit_transform(df['Result'])  \n",
    "df['Gender'] = encoder.fit_transform(df['Gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "318529a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns = [df.columns[0], 'Others'])\n",
    "\n",
    "#Prepare for training and testing\n",
    "X = df.drop(columns = ['Result'])\n",
    "Y = df['Result']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb5e956",
   "metadata": {},
   "source": [
    "## Creation of SMOTE dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3b900ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fa3b3745",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_resampled, Y_resampled = smote.fit_resample(X, Y)\n",
    "\n",
    "df_smote = pd.DataFrame(X_resampled, columns = X.columns)\n",
    "df_smote['Result'] = Y_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "74081aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in df_smote.columns:\n",
    "    df_smote[x] = df_smote[x].apply(lambda x : round(x, 2))       #rounding till 2, but age to int, and haemo to 1\n",
    "\n",
    "df_smote['Age'] = df_smote['Age'].apply(lambda x : int(x))\n",
    "df_smote['Haemoglobin(gms%)'] = df_smote['Haemoglobin(gms%)'].apply(lambda x : round(x, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ca3e4df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_smote.to_csv('../Data/smoteesimedc.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2c83bb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping gender and age columns from both the datasets because we are not considering them\n",
    "df = df.drop(columns = ['Gender', 'Age'])\n",
    "df_smote = df_smote.drop(columns = ['Gender', 'Age'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3a1690",
   "metadata": {},
   "source": [
    "## Training 4 models on 375 dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96d7d27",
   "metadata": {},
   "source": [
    "# End of Model Training and Evaluation\n",
    "\n",
    "All four models have been trained and evaluated on both the original and SMOTE-balanced datasets. Metrics, ROC curves, and confusion matrices are shown above for each case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81cb44ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- LightGBM on df ---\n",
    "import lightgbm as lgb\n",
    "lgb_param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 5, 7, -1],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'num_leaves': [15, 31, 63],\n",
    "    'random_state': [42]\n",
    "}\n",
    "lgb_model = lgb.LGBMClassifier()\n",
    "best_lgb = run_grid_search(lgb_model, lgb_param_grid, X_train_rf, y_train_rf)\n",
    "lgb_stats = evaluate_model(best_lgb, X_test_rf, y_test_rf, model_name=\"LightGBM (df)\")\n",
    "\n",
    "# --- LightGBM on df_smote ---\n",
    "best_lgb_sm = run_grid_search(lgb.LGBMClassifier(), lgb_param_grid, X_train_rf_sm, y_train_rf_sm)\n",
    "lgb_sm_stats = evaluate_model(best_lgb_sm, X_test_rf_sm, y_test_rf_sm, model_name=\"LightGBM (df_smote)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de92a18e",
   "metadata": {},
   "source": [
    "## LightGBM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447a913a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- AdaBoost on df ---\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ada_param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 1.0],\n",
    "    'random_state': [42]\n",
    "}\n",
    "ada_model = AdaBoostClassifier()\n",
    "best_ada = run_grid_search(ada_model, ada_param_grid, X_train_rf, y_train_rf)\n",
    "ada_stats = evaluate_model(best_ada, X_test_rf, y_test_rf, model_name=\"AdaBoost (df)\")\n",
    "\n",
    "# --- AdaBoost on df_smote ---\n",
    "best_ada_sm = run_grid_search(AdaBoostClassifier(), ada_param_grid, X_train_rf_sm, y_train_rf_sm)\n",
    "ada_sm_stats = evaluate_model(best_ada_sm, X_test_rf_sm, y_test_rf_sm, model_name=\"AdaBoost (df_smote)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27f5983",
   "metadata": {},
   "source": [
    "## AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a10dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- XGBoost on df ---\n",
    "import xgboost as xgb\n",
    "xgb_param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0],\n",
    "    'random_state': [42]\n",
    "}\n",
    "xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "best_xgb = run_grid_search(xgb_model, xgb_param_grid, X_train_rf, y_train_rf)\n",
    "xgb_stats = evaluate_model(best_xgb, X_test_rf, y_test_rf, model_name=\"XGBoost (df)\")\n",
    "\n",
    "# --- XGBoost on df_smote ---\n",
    "best_xgb_sm = run_grid_search(xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss'), xgb_param_grid, X_train_rf_sm, y_train_rf_sm)\n",
    "xgb_sm_stats = evaluate_model(best_xgb_sm, X_test_rf_sm, y_test_rf_sm, model_name=\"XGBoost (df_smote)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fee17a",
   "metadata": {},
   "source": [
    "## XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208db310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Random Forest on df ---\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "X_rf = df.drop(columns=['Result'])\n",
    "y_rf = df['Result']\n",
    "X_train_rf, X_test_rf, y_train_rf, y_test_rf = train_test_split(X_rf, y_rf, test_size=0.2, random_state=42, stratify=y_rf)\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 5, 10],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'random_state': [42]\n",
    "}\n",
    "rf_model = RandomForestClassifier()\n",
    "best_rf = run_grid_search(rf_model, rf_param_grid, X_train_rf, y_train_rf)\n",
    "rf_stats = evaluate_model(best_rf, X_test_rf, y_test_rf, model_name=\"Random Forest (df)\")\n",
    "\n",
    "# --- Random Forest on df_smote ---\n",
    "X_rf_sm = df_smote.drop(columns=['Result'])\n",
    "y_rf_sm = df_smote['Result']\n",
    "X_train_rf_sm, X_test_rf_sm, y_train_rf_sm, y_test_rf_sm = train_test_split(X_rf_sm, y_rf_sm, test_size=0.2, random_state=42, stratify=y_rf_sm)\n",
    "best_rf_sm = run_grid_search(RandomForestClassifier(), rf_param_grid, X_train_rf_sm, y_train_rf_sm)\n",
    "rf_sm_stats = evaluate_model(best_rf_sm, X_test_rf_sm, y_test_rf_sm, model_name=\"Random Forest (df_smote)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e6df28",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70f59a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, recall_score, precision_score, confusion_matrix, roc_curve, auc\n",
    "\n",
    "def set_seeds(seed=42):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    try:\n",
    "        import torch\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    except ImportError:\n",
    "        pass\n",
    "    try:\n",
    "        import xgboost as xgb\n",
    "        xgb.random.seed(seed)\n",
    "    except ImportError:\n",
    "        pass\n",
    "    try:\n",
    "        import lightgbm as lgb\n",
    "        lgb.basic._config.set_config(seed=seed)\n",
    "    except Exception:\n",
    "        pass\n",
    "set_seeds(42)\n",
    "\n",
    "def run_grid_search(model, param_grid, X_train, y_train, scoring='f1', cv=5):\n",
    "    grid = GridSearchCV(model, param_grid, scoring=scoring, cv=cv, n_jobs=-1, verbose=1)\n",
    "    grid.fit(X_train, y_train)\n",
    "    print(f\"Best parameters: {grid.best_params_}\")\n",
    "    return grid.best_estimator_\n",
    "\n",
    "def evaluate_model(model, X_test, y_test, model_name=\"Model\", plot_roc=True):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:,1] if hasattr(model, 'predict_proba') else None\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_proba) if y_proba is not None else None\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(f\"{model_name} Test Metrics:\")\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(f\"F1-score: {f1:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    if roc_auc is not None:\n",
    "        print(f\"ROC-AUC: {roc_auc:.4f}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    plt.figure(figsize=(5,4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f\"{model_name} Confusion Matrix\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.show()\n",
    "    if plot_roc and y_proba is not None:\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "        plt.figure(figsize=(5,4))\n",
    "        plt.plot(fpr, tpr, label=f\"ROC curve (area = {roc_auc:.2f})\")\n",
    "        plt.plot([0, 1], [0, 1], 'k--')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title(f\"{model_name} ROC Curve\")\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.show()\n",
    "    return {\"accuracy\": acc, \"f1\": f1, \"roc_auc\": roc_auc, \"recall\": recall, \"precision\": precision, \"confusion_matrix\": cm}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04aa1d77",
   "metadata": {},
   "source": [
    "# Model Training and Evaluation\n",
    "\n",
    "In this section, we train and evaluate four machine learning models (Random Forest, XGBoost, AdaBoost, LightGBM) on two datasets: the original (`df`) and the SMOTE-balanced (`df_smote`).\n",
    "\n",
    "- Hyperparameter tuning is performed using GridSearchCV.\n",
    "- An 80:20 train-test split is used.\n",
    "- All metrics are reported for the test set only.\n",
    "- ROC curves and confusion matrices are displayed for each model.\n",
    "- Random seeds are set for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "eb5c50a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Start of Model Training and Evaluation Section ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd9dcfe",
   "metadata": {},
   "source": [
    "# End of Model Training and Evaluation\n",
    "\n",
    "All four models have been trained and evaluated on both the original and SMOTE-balanced datasets. Metrics, ROC curves, and confusion matrices are shown above for each case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3078532d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'run_grid_search' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[71], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# --- LightGBM on df_smote ---\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m best_lgb_sm \u001b[38;5;241m=\u001b[39m \u001b[43mrun_grid_search\u001b[49m(lgb\u001b[38;5;241m.\u001b[39mLGBMClassifier(), lgb_param_grid, X_train_rf_sm, y_train_rf_sm)\n\u001b[0;32m      3\u001b[0m lgb_sm_stats \u001b[38;5;241m=\u001b[39m evaluate_model(best_lgb_sm, X_test_rf_sm, y_test_rf_sm, model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLightGBM (df_smote)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'run_grid_search' is not defined"
     ]
    }
   ],
   "source": [
    "# --- LightGBM on df_smote ---\n",
    "best_lgb_sm = run_grid_search(lgb.LGBMClassifier(), lgb_param_grid, X_train_rf_sm, y_train_rf_sm)\n",
    "lgb_sm_stats = evaluate_model(best_lgb_sm, X_test_rf_sm, y_test_rf_sm, model_name=\"LightGBM (df_smote)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80de680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- LightGBM on df ---\n",
    "import lightgbm as lgb\n",
    "lgb_param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 5, 7, -1],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'num_leaves': [15, 31, 63],\n",
    "    'random_state': [42]\n",
    "}\n",
    "\n",
    "lgb_model = lgb.LGBMClassifier()\n",
    "best_lgb = run_grid_search(lgb_model, lgb_param_grid, X_train_rf, y_train_rf)\n",
    "lgb_stats = evaluate_model(best_lgb, X_test_rf, y_test_rf, model_name=\"LightGBM (df)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9db5ce6",
   "metadata": {},
   "source": [
    "## LightGBM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d023ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- AdaBoost on df_smote ---\n",
    "best_ada_sm = run_grid_search(AdaBoostClassifier(), ada_param_grid, X_train_rf_sm, y_train_rf_sm)\n",
    "ada_sm_stats = evaluate_model(best_ada_sm, X_test_rf_sm, y_test_rf_sm, model_name=\"AdaBoost (df_smote)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c2265a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- AdaBoost on df ---\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ada_param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 1.0],\n",
    "    'random_state': [42]\n",
    "}\n",
    "\n",
    "ada_model = AdaBoostClassifier()\n",
    "best_ada = run_grid_search(ada_model, ada_param_grid, X_train_rf, y_train_rf)\n",
    "ada_stats = evaluate_model(best_ada, X_test_rf, y_test_rf, model_name=\"AdaBoost (df)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6f7338",
   "metadata": {},
   "source": [
    "## AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a0caa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- XGBoost on df_smote ---\n",
    "best_xgb_sm = run_grid_search(xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss'), xgb_param_grid, X_train_rf_sm, y_train_rf_sm)\n",
    "xgb_sm_stats = evaluate_model(best_xgb_sm, X_test_rf_sm, y_test_rf_sm, model_name=\"XGBoost (df_smote)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a46083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- XGBoost on df ---\n",
    "import xgboost as xgb\n",
    "xgb_param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0],\n",
    "    'random_state': [42]\n",
    "}\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "best_xgb = run_grid_search(xgb_model, xgb_param_grid, X_train_rf, y_train_rf)\n",
    "xgb_stats = evaluate_model(best_xgb, X_test_rf, y_test_rf, model_name=\"XGBoost (df)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b43fe4",
   "metadata": {},
   "source": [
    "## XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1722bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Random Forest on df_smote ---\n",
    "X_rf_sm = df_smote.drop(columns=['Result'])\n",
    "y_rf_sm = df_smote['Result']\n",
    "X_train_rf_sm, X_test_rf_sm, y_train_rf_sm, y_test_rf_sm = train_test_split(X_rf_sm, y_rf_sm, test_size=0.2, random_state=42, stratify=y_rf_sm)\n",
    "\n",
    "best_rf_sm = run_grid_search(RandomForestClassifier(), rf_param_grid, X_train_rf_sm, y_train_rf_sm)\n",
    "rf_sm_stats = evaluate_model(best_rf_sm, X_test_rf_sm, y_test_rf_sm, model_name=\"Random Forest (df_smote)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267d4545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Random Forest on df ---\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X_rf = df.drop(columns=['Result'])\n",
    "y_rf = df['Result']\n",
    "X_train_rf, X_test_rf, y_train_rf, y_test_rf = train_test_split(X_rf, y_rf, test_size=0.2, random_state=42, stratify=y_rf)\n",
    "\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 5, 10],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'random_state': [42]\n",
    "}\n",
    "\n",
    "rf_model = RandomForestClassifier()\n",
    "best_rf = run_grid_search(rf_model, rf_param_grid, X_train_rf, y_train_rf)\n",
    "rf_stats = evaluate_model(best_rf, X_test_rf, y_test_rf, model_name=\"Random Forest (df)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae3a37f",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6631e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_grid_search(model, param_grid, X_train, y_train, scoring='f1', cv=5):\n",
    "    grid = GridSearchCV(model, param_grid, scoring=scoring, cv=cv, n_jobs=-1, verbose=1)\n",
    "    grid.fit(X_train, y_train)\n",
    "    print(f\"Best parameters: {grid.best_params_}\")\n",
    "    return grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fffde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, recall_score, precision_score, confusion_matrix, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def evaluate_model(model, X_test, y_test, model_name=\"Model\", plot_roc=True):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:,1] if hasattr(model, 'predict_proba') else None\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_proba) if y_proba is not None else None\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(f\"{model_name} Test Metrics:\")\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(f\"F1-score: {f1:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    if roc_auc is not None:\n",
    "        print(f\"ROC-AUC: {roc_auc:.4f}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    plt.figure(figsize=(5,4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f\"{model_name} Confusion Matrix\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.show()\n",
    "    if plot_roc and y_proba is not None:\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "        plt.figure(figsize=(5,4))\n",
    "        plt.plot(fpr, tpr, label=f\"ROC curve (area = {roc_auc:.2f})\")\n",
    "        plt.plot([0, 1], [0, 1], 'k--')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title(f\"{model_name} ROC Curve\")\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.show()\n",
    "    return {\"accuracy\": acc, \"f1\": f1, \"roc_auc\": roc_auc, \"recall\": recall, \"precision\": precision, \"confusion_matrix\": cm}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c9c080",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def set_seeds(seed=42):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    try:\n",
    "        import torch\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    except ImportError:\n",
    "        pass\n",
    "    try:\n",
    "        import xgboost as xgb\n",
    "        xgb.random.seed(seed)\n",
    "    except ImportError:\n",
    "        pass\n",
    "    try:\n",
    "        import lightgbm as lgb\n",
    "        lgb.basic._config.set_config(seed=seed)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "set_seeds(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e445f6",
   "metadata": {},
   "source": [
    "# Model Training and Evaluation\n",
    "\n",
    "In this section, we train and evaluate four machine learning models (Random Forest, XGBoost, AdaBoost, LightGBM) on two datasets: the original (`df`) and the SMOTE-balanced (`df_smote`).\n",
    "\n",
    "- Hyperparameter tuning is performed using GridSearchCV.\n",
    "- An 80:20 train-test split is used.\n",
    "- All metrics are reported for the test set only.\n",
    "- ROC curves and confusion matrices are displayed for each model.\n",
    "- Random seeds are set for reproducibility."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
